{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "831f185a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in c:\\users\\pkmpp\\anaconda3\\lib\\site-packages (0.6.1)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\pkmpp\\anaconda3\\lib\\site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.9 in c:\\users\\pkmpp\\anaconda3\\lib\\site-packages (from ollama) (2.12.4)\n",
      "Requirement already satisfied: anyio in c:\\users\\pkmpp\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (4.10.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\pkmpp\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\pkmpp\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\pkmpp\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\pkmpp\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\pkmpp\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\pkmpp\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in c:\\users\\pkmpp\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\pkmpp\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama) (0.4.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\pkmpp\\anaconda3\\lib\\site-packages (from anyio->httpx>=0.27->ollama) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b990e7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2777406347.py, line 8)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mfor i in range response:\u001b[39m\n                   ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "#get ollama models\n",
    "# async def display_models():\n",
    "\n",
    "response = ollama.list()\n",
    "\n",
    "for i in range response:\n",
    "    print(i)\n",
    "\n",
    "\n",
    "# display_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7b1b2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "localModels = ollama.list()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aac6d4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListResponse(models=[Model(model='qwen3_nothink:1.7b-fp16', modified_at=datetime.datetime(2026, 1, 20, 1, 21, 23, 822517, tzinfo=TzInfo(19800)), digest='c81f86c1bfd8b31a43b6a7398bd31130d582fe2793f5755857718f6705405528', size=4069704091, details=ModelDetails(parent_model='', format='gguf', family='qwen3', families=['qwen3'], parameter_size='2.0B', quantization_level='F16')), Model(model='qwen3_nothink:1.7b-q8_0', modified_at=datetime.datetime(2026, 1, 20, 1, 19, 27, 486777, tzinfo=TzInfo(19800)), digest='ba492c43cd9196d4ae42ae10fff960e6b0adf1ed81e959ef81a6527e87c37692', size=2220114332, details=ModelDetails(parent_model='', format='gguf', family='qwen3', families=['qwen3'], parameter_size='2.0B', quantization_level='Q8_0')), Model(model='gemma3:270m-it-bf16', modified_at=datetime.datetime(2026, 1, 17, 0, 3, 41, 406097, tzinfo=TzInfo(19800)), digest='dc598b095ea66b1b9dc15199594a6041f767b573b7a0717047ead63abb83dd60', size=542844530, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='268.10M', quantization_level='BF16')), Model(model='qwen3:1.7b-q8_0', modified_at=datetime.datetime(2026, 1, 15, 18, 57, 10, 704505, tzinfo=TzInfo(19800)), digest='29b6a7a420a42b7d58a17334049721746c35aec6084209ceed327e78a124d15f', size=2220102658, details=ModelDetails(parent_model='', format='gguf', family='qwen3', families=['qwen3'], parameter_size='2.0B', quantization_level='Q8_0')), Model(model='qwen3:1.7b-fp16', modified_at=datetime.datetime(2026, 1, 15, 17, 46, 40, 136110, tzinfo=TzInfo(19800)), digest='e9354f6174db6aa7af338e75b9087e3f4364c255ff96eb20c1805a2f786ed763', size=4069692417, details=ModelDetails(parent_model='', format='gguf', family='qwen3', families=['qwen3'], parameter_size='2.0B', quantization_level='F16')), Model(model='qwen3:0.6b-fp16', modified_at=datetime.datetime(2026, 1, 15, 15, 47, 53, 979817, tzinfo=TzInfo(19800)), digest='626c9556a80fcb9c30ebd28292edf465ccda990282c5fb1e680d106d23bacc1c', size=1509360708, details=ModelDetails(parent_model='', format='gguf', family='qwen3', families=['qwen3'], parameter_size='751.63M', quantization_level='F16')), Model(model='qwen3-embedding:0.6b', modified_at=datetime.datetime(2026, 1, 1, 16, 55, 12, 714402, tzinfo=TzInfo(19800)), digest='ac6da0dfba84a81fdbfbaf330198c33cd77c4cdfc53e8bc50eb581914a15621d', size=639150858, details=ModelDetails(parent_model='', format='gguf', family='qwen3', families=['qwen3'], parameter_size='595.78M', quantization_level='Q8_0')), Model(model='qwen3:4b', modified_at=datetime.datetime(2026, 1, 1, 7, 27, 59, 734218, tzinfo=TzInfo(19800)), digest='359d7dd4bcdab3d86b87d73ac27966f4dbb9f5efdfcc75d34a8764a09474fae7', size=2497293931, details=ModelDetails(parent_model='', format='gguf', family='qwen3', families=['qwen3'], parameter_size='4.0B', quantization_level='Q4_K_M')), Model(model='qwen3:1.7b', modified_at=datetime.datetime(2026, 1, 1, 7, 12, 1, 889489, tzinfo=TzInfo(19800)), digest='8f68893c685c3ddff2aa3fffce2aa60a30bb2da65ca488b61fff134a4d1730e7', size=1359293444, details=ModelDetails(parent_model='', format='gguf', family='qwen3', families=['qwen3'], parameter_size='2.0B', quantization_level='Q4_K_M')), Model(model='gemma3:4b', modified_at=datetime.datetime(2025, 12, 31, 21, 43, 11, 893319, tzinfo=TzInfo(19800)), digest='a2af6cc3eb7fa8be8504abaf9b04e88f17a119ec3f04a3addf55f92841195f5a', size=3338801804, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='4.3B', quantization_level='Q4_K_M')), Model(model='qwen3:0.6b', modified_at=datetime.datetime(2025, 12, 25, 14, 24, 38, 930308, tzinfo=TzInfo(19800)), digest='7df6b6e09427a769808717c0a93cadc4ae99ed4eb8bf5ca557c90846becea435', size=522653767, details=ModelDetails(parent_model='', format='gguf', family='qwen3', families=['qwen3'], parameter_size='751.63M', quantization_level='Q4_K_M')), Model(model='functiongemma:270m', modified_at=datetime.datetime(2025, 12, 20, 17, 0, 34, 802417, tzinfo=TzInfo(19800)), digest='7c19b650567acfb1bee50d12bb286370e8a54d8877f6a0ecfd01f8c8fdc223bb', size=300807157, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='268.10M', quantization_level='Q8_0'))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "localModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f641b78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'qwen3_nothink:1.7b-q8_0'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "localModels[\"models\"][1][\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0086a18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwen3_nothink:1.7b-fp16  :  2.0B\n",
      "qwen3_nothink:1.7b-q8_0  :  2.0B\n",
      "gemma3:270m-it-bf16  :  268.10M\n",
      "qwen3:1.7b-q8_0  :  2.0B\n",
      "qwen3:1.7b-fp16  :  2.0B\n",
      "qwen3:0.6b-fp16  :  751.63M\n",
      "qwen3-embedding:0.6b  :  595.78M\n",
      "qwen3:4b  :  4.0B\n",
      "qwen3:1.7b  :  2.0B\n",
      "gemma3:4b  :  4.3B\n",
      "qwen3:0.6b  :  751.63M\n",
      "functiongemma:270m  :  268.10M\n"
     ]
    }
   ],
   "source": [
    "for model in localModels.models:\n",
    "    print(model.model, \" : \",model.details.parameter_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20d01c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "localModels = ollama.list()\n",
    "\n",
    "model_dict = {\n",
    "    model.model: model.details.parameter_size for model in localModels.models\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fcc2d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "        {\"model\": m.model, \"parameter_size\": m.details.parameter_size} \n",
    "        for m in localModels.models\n",
    "    ]\n",
    "\n",
    "# for model in localModels:\n",
    "#     models.append({\"model\":model.model, \"parameter_size\":model.details.parameter_size })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42b6b0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'qwen3_nothink:1.7b-fp16', 'parameter_size': '2.0B'},\n",
       " {'model': 'qwen3_nothink:1.7b-q8_0', 'parameter_size': '2.0B'},\n",
       " {'model': 'gemma3:270m-it-bf16', 'parameter_size': '268.10M'},\n",
       " {'model': 'qwen3:1.7b-q8_0', 'parameter_size': '2.0B'},\n",
       " {'model': 'qwen3:1.7b-fp16', 'parameter_size': '2.0B'},\n",
       " {'model': 'qwen3:0.6b-fp16', 'parameter_size': '751.63M'},\n",
       " {'model': 'qwen3-embedding:0.6b', 'parameter_size': '595.78M'},\n",
       " {'model': 'qwen3:4b', 'parameter_size': '4.0B'},\n",
       " {'model': 'qwen3:1.7b', 'parameter_size': '2.0B'},\n",
       " {'model': 'gemma3:4b', 'parameter_size': '4.3B'},\n",
       " {'model': 'qwen3:0.6b', 'parameter_size': '751.63M'},\n",
       " {'model': 'functiongemma:270m', 'parameter_size': '268.10M'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6dc136ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qwen3_nothink:1.7b-fp16': '2.0B',\n",
       " 'qwen3_nothink:1.7b-q8_0': '2.0B',\n",
       " 'gemma3:270m-it-bf16': '268.10M',\n",
       " 'qwen3:1.7b-q8_0': '2.0B',\n",
       " 'qwen3:1.7b-fp16': '2.0B',\n",
       " 'qwen3:0.6b-fp16': '751.63M',\n",
       " 'qwen3-embedding:0.6b': '595.78M',\n",
       " 'qwen3:4b': '4.0B',\n",
       " 'qwen3:1.7b': '2.0B',\n",
       " 'gemma3:4b': '4.3B',\n",
       " 'qwen3:0.6b': '751.63M',\n",
       " 'functiongemma:270m': '268.10M'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff825dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'qwen3_nothink:1.7b-fp16': '2.0B', 'qwen3_nothink:1.7b-q8_0': '2.0B', 'gemma3:270m-it-bf16': '268.10M', 'qwen3:1.7b-q8_0': '2.0B', 'qwen3:1.7b-fp16': '2.0B', 'qwen3:0.6b-fp16': '751.63M', 'qwen3-embedding:0.6b': '595.78M', 'qwen3:4b': '4.0B', 'qwen3:1.7b': '2.0B', 'gemma3:4b': '4.3B', 'qwen3:0.6b': '751.63M', 'functiongemma:270m': '268.10M'}\n"
     ]
    }
   ],
   "source": [
    "from helpers import ollama_localmodels\n",
    "\n",
    "print(ollama_localmodels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5741448c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6991a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eae907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006cc8c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d46c26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec3acd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='hello' additional_kwargs={} response_metadata={}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from fastapi import FastAPI\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "from langchain.messages import HumanMessage\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "MODEL_NAME = os.getenv(\"MODEL_NAME\")\n",
    "BASE_URL = os.getenv(\"BASE_URL\")\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model= MODEL_NAME,\n",
    "    base_url=BASE_URL,\n",
    "    api_key=API_KEY\n",
    ")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm\n",
    ")\n",
    "\n",
    "print(HumanMessage(\"hello\"))\n",
    "\n",
    "class ChatRequest(BaseModel):\n",
    "    \"\"\"Schema for the incoming POST request body.\"\"\"\n",
    "    messages: str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82d16248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast feet, fierce pace,  \n",
      "Race against time,  \n",
      "Speed wins the day.\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke(\n",
    "    {\"messages\": {\"role\": \"user\", \"content\": \"Write a haiku about sprinters\"}}\n",
    ")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82f16786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Tell me a Dad joke\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Sure! Here's a dad joke:\n",
      "\n",
      "Why don't skeletons fight each other?  \n",
      "They don't have the guts.\n"
     ]
    }
   ],
   "source": [
    "for step in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Tell me a Dad joke\"}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0843361a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure\n",
      "!\n",
      " Here\n",
      "'s\n",
      " a\n",
      " Dad\n",
      " joke\n",
      ":\n",
      "\n",
      "\n",
      "Why\n",
      " don\n",
      "'t\n",
      " fathers\n",
      " ever\n",
      " get\n",
      " cold\n",
      "?\n",
      "  \n",
      "\n",
      "Because\n",
      " they\n",
      " have\n",
      " a\n",
      " *\n",
      "d\n",
      "ogg\n",
      "ie\n",
      "*\n",
      " wrap\n",
      "!\n",
      " ðŸ˜„\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step,metadata in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Tell me a Dad joke\"}]},\n",
    "    stream_mode=\"messages\", \n",
    "):\n",
    "    print(step.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0617bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='lc_run--019beec2-af46-7641-a231-fbde0d94c862', tool_calls=[], invalid_tool_calls=[], tool_call_chunks=[], chunk_position='last')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
